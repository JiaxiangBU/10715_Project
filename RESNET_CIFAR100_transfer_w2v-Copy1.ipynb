{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, BatchNormalization, Activation, AveragePooling2D, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.datasets import cifar100\n",
    "from keras import backend as K\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'ResNet20v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data and embeddings\n",
    "label_embeddings = pickle.load(open(\"Data/Embeddings/CIFAR/CIFAR_100_label_to_embedding_google_news.pk\", \"rb\"))\n",
    "embedding_len = len(label_embeddings[0])\n",
    "\n",
    "save_dir_feat = os.path.join(os.getcwd(), 'saved_models/%s/extracted_feat/' % (model_type))\n",
    "x_train = np.load(os.path.join(save_dir_feat, 'x_train_feat_cifar100_%s.npy' % (model_type)))\n",
    "x_test = np.load(os.path.join(save_dir_feat, 'x_test_feat_cifar100_%s.npy' % (model_type)))\n",
    "input_shape = x_train[0].shape\n",
    "\n",
    "y_train = cifar100.load_data()[0][1]\n",
    "y_test = cifar100.load_data()[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert train/test labels to embeddings\n",
    "y_train_embeddings = np.zeros((50000, embedding_len))\n",
    "y_test_embeddings = np.zeros((10000, embedding_len))\n",
    "\n",
    "for i in range(y_train.shape[0]):\n",
    "    y_train_embeddings[i] = label_embeddings[int(y_train[i][0])]\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_test_embeddings[i] = label_embeddings[int(y_test[i][0])]\n",
    "\n",
    "label_embeddings_arr = np.zeros((100, embedding_len))\n",
    "for i in range(100):\n",
    "    label_embeddings_arr[i] = label_embeddings[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape=input_shape, embedding_len=embedding_len):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(1024) (x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Dense(512) (x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Dense(embedding_len) (x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    outputs = Dense(embedding_len,\n",
    "                    kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               153900    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               90300     \n",
      "=================================================================\n",
      "Total params: 4,972,696\n",
      "Trainable params: 4,968,512\n",
      "Non-trainable params: 4,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.compile(loss='cosine_proximity', optimizer='adam', metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'saved_models/%s/w2v_transfer/' % (model_type))\n",
    "model_name = 'cifar100_%s_w2v_transfer_model.{epoch:03d}.h5' % (model_type)\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: -0.6590 - mean_squared_error: 3.4811 - val_loss: -0.7019 - val_mean_squared_error: 3.2361\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.70195, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.001.h5\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.8313 - mean_squared_error: 3.5774 - val_loss: -0.7507 - val_mean_squared_error: 4.1881\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.70195 to -0.75070, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.002.h5\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: -0.8864 - mean_squared_error: 4.4274 - val_loss: -0.7598 - val_mean_squared_error: 6.0138\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.75070 to -0.75977, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.003.h5\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9137 - mean_squared_error: 5.0724 - val_loss: -0.7674 - val_mean_squared_error: 6.4417\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.75977 to -0.76736, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.004.h5\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9331 - mean_squared_error: 5.6118 - val_loss: -0.7647 - val_mean_squared_error: 6.1216\n",
      "\n",
      "Epoch 00005: val_loss did not improve from -0.76736\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9463 - mean_squared_error: 6.0646 - val_loss: -0.7530 - val_mean_squared_error: 6.3040\n",
      "\n",
      "Epoch 00006: val_loss did not improve from -0.76736\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9562 - mean_squared_error: 6.4370 - val_loss: -0.7666 - val_mean_squared_error: 6.3509\n",
      "\n",
      "Epoch 00007: val_loss did not improve from -0.76736\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9620 - mean_squared_error: 6.7702 - val_loss: -0.7686 - val_mean_squared_error: 6.0353\n",
      "\n",
      "Epoch 00008: val_loss improved from -0.76736 to -0.76861, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.008.h5\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: -0.9662 - mean_squared_error: 7.0951 - val_loss: -0.7675 - val_mean_squared_error: 6.5177\n",
      "\n",
      "Epoch 00009: val_loss did not improve from -0.76861\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9700 - mean_squared_error: 7.3755 - val_loss: -0.7684 - val_mean_squared_error: 6.7637\n",
      "\n",
      "Epoch 00010: val_loss did not improve from -0.76861\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: -0.9736 - mean_squared_error: 7.6312 - val_loss: -0.7642 - val_mean_squared_error: 6.8327\n",
      "\n",
      "Epoch 00011: val_loss did not improve from -0.76861\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: -0.9759 - mean_squared_error: 7.8687 - val_loss: -0.7616 - val_mean_squared_error: 7.0775\n",
      "\n",
      "Epoch 00012: val_loss did not improve from -0.76861\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: -0.9782 - mean_squared_error: 8.0927 - val_loss: -0.7638 - val_mean_squared_error: 8.2305\n",
      "\n",
      "Epoch 00013: val_loss did not improve from -0.76861\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9841 - mean_squared_error: 8.2213 - val_loss: -0.7783 - val_mean_squared_error: 7.6273\n",
      "\n",
      "Epoch 00014: val_loss improved from -0.76861 to -0.77834, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.014.h5\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9875 - mean_squared_error: 8.2168 - val_loss: -0.7778 - val_mean_squared_error: 7.4887\n",
      "\n",
      "Epoch 00015: val_loss did not improve from -0.77834\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: -0.9888 - mean_squared_error: 8.2144 - val_loss: -0.7775 - val_mean_squared_error: 7.5556\n",
      "\n",
      "Epoch 00016: val_loss did not improve from -0.77834\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: -0.9897 - mean_squared_error: 8.2142 - val_loss: -0.7768 - val_mean_squared_error: 7.3626\n",
      "\n",
      "Epoch 00017: val_loss did not improve from -0.77834\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: -0.9901 - mean_squared_error: 8.2256 - val_loss: -0.7782 - val_mean_squared_error: 7.8225\n",
      "\n",
      "Epoch 00018: val_loss did not improve from -0.77834\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: -0.9908 - mean_squared_error: 8.2291 - val_loss: -0.7779 - val_mean_squared_error: 7.5610\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -0.77834\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: -0.9918 - mean_squared_error: 8.2442 - val_loss: -0.7800 - val_mean_squared_error: 7.4634\n",
      "\n",
      "Epoch 00020: val_loss improved from -0.77834 to -0.77998, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.020.h5\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9921 - mean_squared_error: 8.2420 - val_loss: -0.7794 - val_mean_squared_error: 7.4786\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -0.77998\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9924 - mean_squared_error: 8.2357 - val_loss: -0.7801 - val_mean_squared_error: 7.4007\n",
      "\n",
      "Epoch 00022: val_loss improved from -0.77998 to -0.78005, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.022.h5\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9926 - mean_squared_error: 8.2289 - val_loss: -0.7799 - val_mean_squared_error: 7.2798\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -0.78005\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: -0.9928 - mean_squared_error: 8.2233 - val_loss: -0.7798 - val_mean_squared_error: 7.3120\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -0.78005\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: -0.9929 - mean_squared_error: 8.2245 - val_loss: -0.7793 - val_mean_squared_error: 7.4076\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -0.78005\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: -0.9931 - mean_squared_error: 8.2235 - val_loss: -0.7801 - val_mean_squared_error: 7.3131\n",
      "\n",
      "Epoch 00026: val_loss improved from -0.78005 to -0.78012, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.026.h5\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9933 - mean_squared_error: 8.2213 - val_loss: -0.7806 - val_mean_squared_error: 7.3866\n",
      "\n",
      "Epoch 00027: val_loss improved from -0.78012 to -0.78060, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.027.h5\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: -0.9934 - mean_squared_error: 8.2203 - val_loss: -0.7806 - val_mean_squared_error: 7.2956\n",
      "\n",
      "Epoch 00028: val_loss improved from -0.78060 to -0.78062, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.028.h5\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9934 - mean_squared_error: 8.2173 - val_loss: -0.7806 - val_mean_squared_error: 7.3048\n",
      "\n",
      "Epoch 00029: val_loss improved from -0.78062 to -0.78063, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.029.h5\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9935 - mean_squared_error: 8.2189 - val_loss: -0.7806 - val_mean_squared_error: 7.2038\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -0.78063\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9937 - mean_squared_error: 8.2168 - val_loss: -0.7805 - val_mean_squared_error: 7.3083\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -0.78063\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9936 - mean_squared_error: 8.2120 - val_loss: -0.7805 - val_mean_squared_error: 7.3593\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -0.78063\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: -0.9936 - mean_squared_error: 8.2088 - val_loss: -0.7804 - val_mean_squared_error: 7.3210\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -0.78063\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: -0.9937 - mean_squared_error: 8.2119 - val_loss: -0.7803 - val_mean_squared_error: 7.3774\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -0.78063\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: -0.9936 - mean_squared_error: 8.2121 - val_loss: -0.7803 - val_mean_squared_error: 7.3220\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -0.78063\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9938 - mean_squared_error: 8.2101 - val_loss: -0.7804 - val_mean_squared_error: 7.3084\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -0.78063\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: -0.9938 - mean_squared_error: 8.2092 - val_loss: -0.7805 - val_mean_squared_error: 7.3607\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -0.78063\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9939 - mean_squared_error: 8.2071 - val_loss: -0.7806 - val_mean_squared_error: 7.3068\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -0.78063\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9938 - mean_squared_error: 8.2090 - val_loss: -0.7807 - val_mean_squared_error: 7.3031\n",
      "\n",
      "Epoch 00039: val_loss improved from -0.78063 to -0.78067, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.039.h5\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: -0.9938 - mean_squared_error: 8.2070 - val_loss: -0.7808 - val_mean_squared_error: 7.2581\n",
      "\n",
      "Epoch 00040: val_loss improved from -0.78067 to -0.78080, saving model to /home/tliu/Dev/CMU/10-715/10715_Project/saved_models/ResNet20v2/w2v_transfer/cifar100_ResNet20v2_w2v_transfer_model.040.h5\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9939 - mean_squared_error: 8.2107 - val_loss: -0.7804 - val_mean_squared_error: 7.3075\n",
      "\n",
      "Epoch 00041: val_loss did not improve from -0.78080\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: -0.9939 - mean_squared_error: 8.2062 - val_loss: -0.7804 - val_mean_squared_error: 7.2245\n",
      "\n",
      "Epoch 00042: val_loss did not improve from -0.78080\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9938 - mean_squared_error: 8.2082 - val_loss: -0.7804 - val_mean_squared_error: 7.2455\n",
      "\n",
      "Epoch 00043: val_loss did not improve from -0.78080\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: -0.9938 - mean_squared_error: 8.2068 - val_loss: -0.7802 - val_mean_squared_error: 7.3090\n",
      "\n",
      "Epoch 00044: val_loss did not improve from -0.78080\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: -0.9938 - mean_squared_error: 8.2097 - val_loss: -0.7805 - val_mean_squared_error: 7.3085\n",
      "\n",
      "Epoch 00045: val_loss did not improve from -0.78080\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9939 - mean_squared_error: 8.2091 - val_loss: -0.7806 - val_mean_squared_error: 7.2411\n",
      "\n",
      "Epoch 00046: val_loss did not improve from -0.78080\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9939 - mean_squared_error: 8.2067 - val_loss: -0.7801 - val_mean_squared_error: 7.2743\n",
      "\n",
      "Epoch 00047: val_loss did not improve from -0.78080\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9938 - mean_squared_error: 8.2117 - val_loss: -0.7803 - val_mean_squared_error: 7.2413\n",
      "\n",
      "Epoch 00048: val_loss did not improve from -0.78080\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9939 - mean_squared_error: 8.2065 - val_loss: -0.7803 - val_mean_squared_error: 7.2632\n",
      "\n",
      "Epoch 00049: val_loss did not improve from -0.78080\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: -0.9937 - mean_squared_error: 8.2063 - val_loss: -0.7804 - val_mean_squared_error: 7.2420\n",
      "\n",
      "Epoch 00050: val_loss did not improve from -0.78080\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: -0.9939 - mean_squared_error: 8.2043 - val_loss: -0.7806 - val_mean_squared_error: 7.3065\n",
      "\n",
      "Epoch 00051: val_loss did not improve from -0.78080\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: -0.9939 - mean_squared_error: 8.2055 - val_loss: -0.7807 - val_mean_squared_error: 7.2036\n",
      "\n",
      "Epoch 00052: val_loss did not improve from -0.78080\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: -0.9939 - mean_squared_error: 8.2099 - val_loss: -0.7805 - val_mean_squared_error: 7.3264\n",
      "\n",
      "Epoch 00053: val_loss did not improve from -0.78080\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9938 - mean_squared_error: 8.2122 - val_loss: -0.7802 - val_mean_squared_error: 7.2998\n",
      "\n",
      "Epoch 00054: val_loss did not improve from -0.78080\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: -0.9940 - mean_squared_error: 8.2044 - val_loss: -0.7804 - val_mean_squared_error: 7.2781\n",
      "\n",
      "Epoch 00055: val_loss did not improve from -0.78080\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9939 - mean_squared_error: 8.2073 - val_loss: -0.7802 - val_mean_squared_error: 7.3042\n",
      "\n",
      "Epoch 00056: val_loss did not improve from -0.78080\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9939 - mean_squared_error: 8.2087 - val_loss: -0.7805 - val_mean_squared_error: 7.2962\n",
      "\n",
      "Epoch 00057: val_loss did not improve from -0.78080\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: -0.9939 - mean_squared_error: 8.2066 - val_loss: -0.7803 - val_mean_squared_error: 7.2493\n",
      "\n",
      "Epoch 00058: val_loss did not improve from -0.78080\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: -0.9938 - mean_squared_error: 8.2072 - val_loss: -0.7806 - val_mean_squared_error: 7.2166\n",
      "\n",
      "Epoch 00059: val_loss did not improve from -0.78080\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: -0.9939 - mean_squared_error: 8.2082 - val_loss: -0.7805 - val_mean_squared_error: 7.2961\n",
      "\n",
      "Epoch 00060: val_loss did not improve from -0.78080\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: -0.9939 - mean_squared_error: 8.2081 - val_loss: -0.7808 - val_mean_squared_error: 7.3161\n",
      "\n",
      "Epoch 00061: val_loss did not improve from -0.78080\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: -0.9939 - mean_squared_error: 8.2121 - val_loss: -0.7805 - val_mean_squared_error: 7.3132\n",
      "\n",
      "Epoch 00062: val_loss did not improve from -0.78080\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: -0.9940 - mean_squared_error: 8.2079 - val_loss: -0.7803 - val_mean_squared_error: 7.3045\n",
      "\n",
      "Epoch 00063: val_loss did not improve from -0.78080\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: -0.9939 - mean_squared_error: 8.2080 - val_loss: -0.7806 - val_mean_squared_error: 7.3106\n",
      "\n",
      "Epoch 00064: val_loss did not improve from -0.78080\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 110us/step - loss: -0.9938 - mean_squared_error: 8.2045 - val_loss: -0.7806 - val_mean_squared_error: 7.3058\n",
      "\n",
      "Epoch 00065: val_loss did not improve from -0.78080\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: -0.9940 - mean_squared_error: 8.2064 - val_loss: -0.7805 - val_mean_squared_error: 7.2545\n",
      "\n",
      "Epoch 00066: val_loss did not improve from -0.78080\n",
      "Epoch 67/100\n",
      " 4096/50000 [=>............................] - ETA: 4s - loss: -0.9937 - mean_squared_error: 8.2119"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-79748122755a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m          )\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train_embeddings,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test_embeddings),\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks,\n",
    "          verbose=1\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top K Predictions\n",
    "def pred_top_k(y_test_pred, label_embeddings_arr=label_embeddings_arr, k=5):\n",
    "    sim_table = cosine_similarity(y_test_pred, label_embeddings_arr)\n",
    "    top_k_guesses = np.argpartition(sim_table,range(99-k+1,100),axis=1)[:,99-k+1:]\n",
    "    return sim_table, top_k_guesses\n",
    "\n",
    "#Top k Accuracy\n",
    "def calc_top_k_acc(top_k, y_test):\n",
    "    correct = 0\n",
    "    for i in range(y_test.shape[0]):\n",
    "        if np.squeeze(y_test)[i] in top_k[i]:\n",
    "            correct += 1\n",
    "    return correct/float(y_test.shape[0])\n",
    "\n",
    "def evaluate(model, x_test, y_test, label_embeddings_arr, k=5):\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    sim_table, top_k_guesses = pred_top_k(y_test_pred, label_embeddings_arr, k=k)\n",
    "\n",
    "    #Top prediction\n",
    "    label_predictions = sim_table.argmax(axis=1)\n",
    "    \n",
    "    #Accuracy\n",
    "    acc = np.sum((np.squeeze(y_test) == label_predictions)) / float(y_test.shape[0])\n",
    "    top_k_acc = calc_top_k_acc(top_k_guesses, y_test)\n",
    "    print(\"Accuracy: \" + str(acc))\n",
    "    print(\"Top \" + str(k) + \" Accuracy: \" + str(top_k_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6419\n",
      "Top 5 Accuracy: 0.7704\n"
     ]
    }
   ],
   "source": [
    "best_model_filepath = os.path.join(save_dir, 'cifar100_%s_w2v_transfer_model.%03d.h5' % (model_type, 40))\n",
    "best_model = load_model(best_model_filepath)\n",
    "\n",
    "evaluate(best_model, x_test, y_test, label_embeddings_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99894\n",
      "Top 5 Accuracy: 0.99958\n"
     ]
    }
   ],
   "source": [
    "evalute(best_model, x_train, y_train, label_embeddings_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Top K Accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0,99,100) \n",
    "y = np.zeros(100)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "for i in range(100):\n",
    "    k = i+1\n",
    "    sim_table, top_k_guesses = pred_top_k(y_test_pred, k=k)\n",
    "    y[i] = calc_top_k_acc(top_k_guesses, y_test)\n",
    "    \n",
    "plt.plot(x,y)\n",
    "plt.title(\"Top K Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = build_model()\n",
    "model.compile(loss='cosine_proximity', optimizer='adam', metrics=['mse'])\n",
    "model.summary()\n",
    "\n",
    "for i in range(epochs):\n",
    "    print('Epoch: %d/%d' % (i+1, epochs))\n",
    "    model.fit(x_train, y_train_embeddings,\n",
    "              batch_size=batch_size,\n",
    "              epochs=1,\n",
    "              validation_data=(x_test, y_test_embeddings),\n",
    "              shuffle=True,\n",
    "              verbose=1\n",
    "             )\n",
    "    evalute(model, x_test, y_test, label_embeddings_arr)\n",
    "    print('\\n')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
