{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model, and generate new transformed dataset by passing images through pretrained model \n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.datasets import cifar100\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights=None,include_top=False,input_shape=(32, 32, 3))\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model \n",
    "conv_base = VGG16(weights='imagenet',include_top=False,input_shape=(32, 32, 3))\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=conv_base.output_shape[1:]))\n",
    "\n",
    "top_model.add(Dense(512, activation='relu'))\n",
    "top_model.add(BatchNormalization())\n",
    "top_model.add(Dense(512, activation='relu'))\n",
    "top_model.add(BatchNormalization())\n",
    "top_model.add(Dense(100, activation='softmax'))\n",
    "for layer in top_model.layers:\n",
    "    layer.trainable = True \n",
    "\n",
    "final_model = Model(inputs=conv_base.input, outputs=top_model(conv_base.output))\n",
    "final_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 100\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 25\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "generator_train = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "generator_test = datagen.flow(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1562/1562 [==============================] - 20s 13ms/step - loss: 3.1700 - acc: 0.2438 - val_loss: 2.8806 - val_acc: 0.2895\n",
      "Epoch 2/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 2.6995 - acc: 0.3199 - val_loss: 2.7246 - val_acc: 0.3213\n",
      "Epoch 3/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 2.5229 - acc: 0.3533 - val_loss: 2.6329 - val_acc: 0.3400\n",
      "Epoch 4/25\n",
      "1562/1562 [==============================] - 18s 12ms/step - loss: 2.3945 - acc: 0.3793 - val_loss: 2.6360 - val_acc: 0.3484\n",
      "Epoch 5/25\n",
      "1562/1562 [==============================] - 18s 12ms/step - loss: 2.2888 - acc: 0.4019 - val_loss: 2.6051 - val_acc: 0.3490\n",
      "Epoch 6/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 2.1890 - acc: 0.4238 - val_loss: 2.6031 - val_acc: 0.3564\n",
      "Epoch 7/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 2.0880 - acc: 0.4435 - val_loss: 2.6331 - val_acc: 0.3534\n",
      "Epoch 8/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.9980 - acc: 0.4654 - val_loss: 2.6584 - val_acc: 0.3599\n",
      "Epoch 9/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.9201 - acc: 0.4806 - val_loss: 2.6670 - val_acc: 0.3570\n",
      "Epoch 10/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.8341 - acc: 0.5002 - val_loss: 2.6898 - val_acc: 0.3614\n",
      "Epoch 11/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.7583 - acc: 0.5183 - val_loss: 2.7421 - val_acc: 0.3610\n",
      "Epoch 12/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.6839 - acc: 0.5334 - val_loss: 2.7858 - val_acc: 0.3554\n",
      "Epoch 13/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.6130 - acc: 0.5522 - val_loss: 2.8627 - val_acc: 0.3539\n",
      "Epoch 14/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.5488 - acc: 0.5679 - val_loss: 2.8875 - val_acc: 0.3540\n",
      "Epoch 15/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.4807 - acc: 0.5824 - val_loss: 2.9732 - val_acc: 0.3534\n",
      "Epoch 16/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.4241 - acc: 0.5972 - val_loss: 3.0592 - val_acc: 0.3526\n",
      "Epoch 17/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.3640 - acc: 0.6099 - val_loss: 3.0714 - val_acc: 0.3527\n",
      "Epoch 18/25\n",
      "1562/1562 [==============================] - 18s 12ms/step - loss: 1.3171 - acc: 0.6222 - val_loss: 3.0820 - val_acc: 0.3557\n",
      "Epoch 19/25\n",
      "1562/1562 [==============================] - 18s 12ms/step - loss: 1.2608 - acc: 0.6374 - val_loss: 3.1998 - val_acc: 0.3428\n",
      "Epoch 20/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.2229 - acc: 0.6445 - val_loss: 3.2377 - val_acc: 0.3550\n",
      "Epoch 21/25\n",
      "1562/1562 [==============================] - 18s 12ms/step - loss: 1.1820 - acc: 0.6540 - val_loss: 3.3468 - val_acc: 0.3489\n",
      "Epoch 22/25\n",
      "1562/1562 [==============================] - 18s 12ms/step - loss: 1.1291 - acc: 0.6688 - val_loss: 3.3828 - val_acc: 0.3452\n",
      "Epoch 23/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.0968 - acc: 0.6761 - val_loss: 3.4091 - val_acc: 0.3425\n",
      "Epoch 24/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.0586 - acc: 0.6855 - val_loss: 3.4946 - val_acc: 0.3396\n",
      "Epoch 25/25\n",
      "1562/1562 [==============================] - 19s 12ms/step - loss: 1.0282 - acc: 0.6940 - val_loss: 3.4908 - val_acc: 0.3420\n"
     ]
    }
   ],
   "source": [
    "history = final_model.fit_generator(generator=generator_train,\n",
    "                                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                                    epochs=epochs,\n",
    "                                    validation_data=generator_test,\n",
    "                                    validation_steps=x_test.shape[0] // batch_size\n",
    "                                   )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
