{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "import pickle\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data and embeddings\n",
    "label_embeddings = pickle.load(open(\"Data/Embeddings/CIFAR/CIFAR_100_label_to_embedding_google_news.pk\", \"rb\"))\n",
    "train_x = np.load(\"vgg_16/train_x.npy\").reshape((50000,-1))\n",
    "train_y = np.load(\"vgg_16/train_y.npy\")\n",
    "test_x = np.load(\"vgg_16/test_x.npy\").reshape((10000,-1))\n",
    "test_y = np.load(\"vgg_16/test_y.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert train/test labels to embeddings\n",
    "train_y_embeddings = np.zeros((50000, 300))\n",
    "test_y_embeddings = np.zeros((10000, 300))\n",
    "\n",
    "for i in range(train_y.shape[0]):\n",
    "    train_y_embeddings[i] = label_embeddings[int(train_y[i][0])]\n",
    "\n",
    "for i in range(test_y.shape[0]):\n",
    "    test_y_embeddings[i] = label_embeddings[int(test_y[i][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dense(300, input_dim=300, activation='relu'))\n",
    "model.add(Dense(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_distance(y_true, y_pred):\n",
    "    def l2_normalize(x, axis):\n",
    "        norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=True))\n",
    "        return K.sign(x) * K.maximum(K.abs(x), K.epsilon()) / K.maximum(norm, K.epsilon())\n",
    "    y_true = l2_normalize(y_true, axis=-1)\n",
    "    y_pred = l2_normalize(y_pred, axis=-1)\n",
    "    return K.mean(y_true * y_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['cosine_proximity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.0508 - cosine_proximity: -0.5092 - val_loss: 0.0243 - val_cosine_proximity: -0.5855\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0194 - cosine_proximity: -0.6820 - val_loss: 0.0216 - val_cosine_proximity: -0.6320\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0163 - cosine_proximity: -0.7388 - val_loss: 0.0202 - val_cosine_proximity: -0.6594\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0144 - cosine_proximity: -0.7717 - val_loss: 0.0199 - val_cosine_proximity: -0.6692\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0130 - cosine_proximity: -0.7948 - val_loss: 0.0192 - val_cosine_proximity: -0.6807\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0121 - cosine_proximity: -0.8110 - val_loss: 0.0192 - val_cosine_proximity: -0.6815\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0113 - cosine_proximity: -0.8238 - val_loss: 0.0188 - val_cosine_proximity: -0.6903\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0108 - cosine_proximity: -0.8335 - val_loss: 0.0186 - val_cosine_proximity: -0.6934\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0103 - cosine_proximity: -0.8414 - val_loss: 0.0186 - val_cosine_proximity: -0.6936\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0099 - cosine_proximity: -0.8472 - val_loss: 0.0185 - val_cosine_proximity: -0.6972\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0097 - cosine_proximity: -0.8519 - val_loss: 0.0185 - val_cosine_proximity: -0.6969\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0094 - cosine_proximity: -0.8563 - val_loss: 0.0184 - val_cosine_proximity: -0.7003\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0092 - cosine_proximity: -0.8603 - val_loss: 0.0181 - val_cosine_proximity: -0.7024\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0089 - cosine_proximity: -0.8637 - val_loss: 0.0179 - val_cosine_proximity: -0.7073\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0087 - cosine_proximity: -0.8670 - val_loss: 0.0178 - val_cosine_proximity: -0.7064\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0086 - cosine_proximity: -0.8689 - val_loss: 0.0181 - val_cosine_proximity: -0.7032\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0084 - cosine_proximity: -0.8718 - val_loss: 0.0179 - val_cosine_proximity: -0.7082\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0083 - cosine_proximity: -0.8744 - val_loss: 0.0179 - val_cosine_proximity: -0.7054\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0081 - cosine_proximity: -0.8765 - val_loss: 0.0178 - val_cosine_proximity: -0.7085\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0080 - cosine_proximity: -0.8784 - val_loss: 0.0177 - val_cosine_proximity: -0.7096\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0079 - cosine_proximity: -0.8804 - val_loss: 0.0178 - val_cosine_proximity: -0.7078\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0078 - cosine_proximity: -0.8821 - val_loss: 0.0178 - val_cosine_proximity: -0.7095\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0076 - cosine_proximity: -0.8843 - val_loss: 0.0177 - val_cosine_proximity: -0.7095\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0075 - cosine_proximity: -0.8860 - val_loss: 0.0177 - val_cosine_proximity: -0.7085\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0074 - cosine_proximity: -0.8873 - val_loss: 0.0177 - val_cosine_proximity: -0.7094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e7618ab38>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y_embeddings, epochs=25, batch_size=128, validation_data=(test_x, test_y_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = model.predict(test_x)\n",
    "\n",
    "label_embeddings\n",
    "label_embeddings_arr = np.zeros((100, 300))\n",
    "for i in range(100):\n",
    "    label_embeddings_arr[i] = label_embeddings[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top K Predictions\n",
    "def pred_top_k(k=5, pred_test_y=pred_test_y, label_embeddings_arr=label_embeddings_arr):\n",
    "    sim_table = cosine_similarity(pred_test_y, label_embeddings_arr)\n",
    "    top_k_guesses = np.argpartition(sim_table,range(99-k+1,100),axis=1)[:,99-k+1:]\n",
    "    return top_k_guesses\n",
    "\n",
    "\n",
    "#Top prediction\n",
    "sim_table = cosine_similarity(pred_test_y, label_embeddings_arr)\n",
    "label_predictions = sim_table.argmax(axis=1)\n",
    "label_predictions\n",
    "\n",
    "k=5\n",
    "top_k_guesses = pred_top_k(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.524\n",
      "Top 5 Accuracy: 0.697\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "acc = np.sum((np.squeeze(test_y) == label_predictions)) / float(test_y.shape[0])\n",
    "print(\"Accuracy: \" + str(acc))\n",
    "\n",
    "#Top k Accuracy\n",
    "\n",
    "def acc(top_k=top_k_guesses, test_y=test_y):\n",
    "    correct = 0\n",
    "    for i in range(test_y.shape[0]):\n",
    "        if np.squeeze(test_y)[i] in top_k[i]:\n",
    "            correct += 1\n",
    "    return correct/float(test_y.shape[0])\n",
    "\n",
    "print(\"Top \" + str(k) + \" Accuracy: \" + str(acc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ny = np.zeros(100)\n",
    "\n",
    "y = np.linspace(0,99,100)\n",
    "for i in range(100):\n",
    "    k = i+1\n",
    "    top_k_guesses = pred_top_k(k)\n",
    "    y[i] = acc(top_k_guesses, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Top K Accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y)\n",
    "plt.title(\"Top K Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
